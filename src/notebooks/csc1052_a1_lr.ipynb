{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook trains a binary classifier on a dataset which contains movie reviews which are labelled as containing either *positive* or *negative* sentiment towards the movie."
      ],
      "metadata": {
        "id": "fsF8yRafNKjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will install *sklearn* which we will be using to do the machine learning."
      ],
      "metadata": {
        "id": "nzUZxeMbRPoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8dcUsoOA_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a4800e-a80d-4d0a-dc70-168d4a713ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will install the dataset. We will use the IMDB sentiment analysis dataset available from the [huggingface datasets library](https://huggingface.co/datasets/imdb) and described in [Maas et al. 2011](https://aclanthology.org/P11-1015.pdf)."
      ],
      "metadata": {
        "id": "ekmP1Ry1R00y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "yd0bLG6nOE4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4220261d-f7e7-446d-c5d2-83d476ddde43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the IMDB training set. We will print out the last instance."
      ],
      "metadata": {
        "id": "2h6B6dXHSP6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")['train']\n",
        "print(imdb_dataset[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOO5rQFHUg8D",
        "outputId": "60223425-2877-4e17-8860-833bf0fc9650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.', 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's convert the training data into the format expected by scikit-learn - a list of input vectors (documents) and a list of associated output labels."
      ],
      "metadata": {
        "id": "enwDYpN7Hwgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_data_labels = []\n",
        "for item in imdb_dataset:\n",
        "  train_data.append(item['text'])\n",
        "  train_data_labels.append(item['label'])\n",
        "print(train_data[-1])\n",
        "print(train_data_labels[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xfDeEMWq1o",
        "outputId": "80c0ceb8-ddb3-42f8-d31e-c6a676704678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the CountVectorizer class to extract the words in each review as the features the algorithm will learn from. Each document is represented as a 500 dimension vector of word counts. Only the 500 most frequent words are used in this version."
      ],
      "metadata": {
        "id": "wI6ab7wOIOu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='word',max_features=500,lowercase=True)\n",
        "features = vectorizer.fit_transform(train_data).toarray()"
      ],
      "metadata": {
        "id": "vDYo_rZkXZUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check, let's check we have a 2-d array where each row is one of the 25,000 instances and each column is one of 200 words. Print out the words that will be used for classification."
      ],
      "metadata": {
        "id": "W7l9Xg1TTfkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape)\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oW0zYH0TdPm",
        "outputId": "2b04d924-d583-42d3-d2df-2f060e41bff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 500)\n",
            "['10' 'able' 'about' 'absolutely' 'act' 'acting' 'action' 'actor' 'actors'\n",
            " 'actress' 'actually' 'after' 'again' 'against' 'all' 'almost' 'along'\n",
            " 'already' 'also' 'although' 'always' 'am' 'amazing' 'american' 'an' 'and'\n",
            " 'another' 'any' 'anyone' 'anything' 'are' 'around' 'art' 'as' 'at'\n",
            " 'audience' 'away' 'awful' 'back' 'bad' 'based' 'be' 'beautiful' 'because'\n",
            " 'become' 'becomes' 'been' 'before' 'beginning' 'behind' 'being' 'believe'\n",
            " 'best' 'better' 'between' 'big' 'bit' 'black' 'book' 'boring' 'both'\n",
            " 'boy' 'br' 'budget' 'but' 'by' 'called' 'came' 'camera' 'can' 'car'\n",
            " 'care' 'case' 'cast' 'certainly' 'character' 'characters' 'child'\n",
            " 'children' 'cinema' 'classic' 'close' 'come' 'comedy' 'comes'\n",
            " 'completely' 'could' 'couldn' 'couple' 'course' 'dark' 'day' 'days'\n",
            " 'dead' 'death' 'definitely' 'despite' 'dialogue' 'did' 'didn' 'different'\n",
            " 'direction' 'director' 'do' 'does' 'doesn' 'doing' 'don' 'done' 'down'\n",
            " 'drama' 'during' 'dvd' 'each' 'early' 'effects' 'either' 'else' 'end'\n",
            " 'ending' 'enjoy' 'enjoyed' 'enough' 'entertaining' 'entire' 'episode'\n",
            " 'especially' 'even' 'ever' 'every' 'everyone' 'everything' 'evil'\n",
            " 'example' 'excellent' 'face' 'fact' 'family' 'fan' 'fans' 'far' 'father'\n",
            " 'favorite' 'feel' 'felt' 'few' 'film' 'films' 'final' 'finally' 'find'\n",
            " 'fine' 'first' 'flick' 'for' 'found' 'friend' 'friends' 'from' 'full'\n",
            " 'fun' 'funny' 'game' 'genre' 'get' 'gets' 'getting' 'girl' 'give' 'given'\n",
            " 'gives' 'go' 'goes' 'going' 'good' 'got' 'great' 'guess' 'guy' 'guys'\n",
            " 'had' 'half' 'hand' 'hard' 'has' 'have' 'having' 'he' 'head' 'heart'\n",
            " 'help' 'her' 'here' 'high' 'him' 'himself' 'his' 'history' 'hollywood'\n",
            " 'home' 'hope' 'horror' 'house' 'how' 'however' 'human' 'humor' 'idea'\n",
            " 'if' 'in' 'instead' 'interesting' 'into' 'is' 'isn' 'it' 'its' 'itself'\n",
            " 'job' 'john' 'just' 'keep' 'kids' 'kill' 'killer' 'kind' 'know' 'last'\n",
            " 'later' 'laugh' 'lead' 'least' 'left' 'less' 'let' 'life' 'like' 'liked'\n",
            " 'line' 'lines' 'little' 'live' 'lives' 'll' 'long' 'look' 'looking'\n",
            " 'looks' 'lost' 'lot' 'love' 'loved' 'low' 'made' 'main' 'make' 'makes'\n",
            " 'making' 'man' 'many' 'may' 'maybe' 'me' 'mean' 'men' 'michael' 'might'\n",
            " 'mind' 'minutes' 'moments' 'money' 'more' 'most' 'mother' 'movie'\n",
            " 'movies' 'mr' 'much' 'music' 'must' 'my' 'name' 'need' 'never' 'new'\n",
            " 'next' 'nice' 'night' 'no' 'not' 'nothing' 'now' 'of' 'off' 'often' 'oh'\n",
            " 'old' 'on' 'once' 'one' 'only' 'or' 'original' 'other' 'others' 'our'\n",
            " 'out' 'over' 'overall' 'own' 'part' 'past' 'people' 'perfect'\n",
            " 'performance' 'performances' 'perhaps' 'person' 'picture' 'piece' 'place'\n",
            " 'play' 'played' 'playing' 'plays' 'plot' 'point' 'poor' 'pretty'\n",
            " 'probably' 'problem' 'production' 'put' 'quality' 'quite' 'rather' 're'\n",
            " 'read' 'real' 'really' 'reason' 'recommend' 'remember' 'rest' 'right'\n",
            " 'role' 'said' 'same' 'saw' 'say' 'scene' 'scenes' 'school' 'screen'\n",
            " 'script' 'second' 'see' 'seeing' 'seem' 'seemed' 'seems' 'seen' 'sense'\n",
            " 'series' 'set' 'several' 'sex' 'she' 'short' 'shot' 'should' 'show'\n",
            " 'shows' 'side' 'simply' 'since' 'small' 'so' 'some' 'someone' 'something'\n",
            " 'son' 'soon' 'sort' 'sound' 'special' 'star' 'stars' 'start' 'still'\n",
            " 'story' 'stupid' 'style' 'such' 'supposed' 'sure' 'take' 'takes' 'tell'\n",
            " 'terrible' 'than' 'that' 'the' 'their' 'them' 'then' 'there' 'these'\n",
            " 'they' 'thing' 'things' 'think' 'this' 'those' 'though' 'thought' 'three'\n",
            " 'through' 'throughout' 'time' 'times' 'title' 'to' 'today' 'together'\n",
            " 'too' 'top' 'totally' 'town' 'tries' 'true' 'truly' 'try' 'trying' 'turn'\n",
            " 'turns' 'tv' 'two' 'under' 'understand' 'unfortunately' 'until' 'up' 'us'\n",
            " 'use' 'used' 've' 'version' 'very' 'video' 'viewer' 'want' 'wanted'\n",
            " 'wants' 'war' 'was' 'wasn' 'waste' 'watch' 'watched' 'watching' 'way'\n",
            " 'we' 'well' 'went' 'were' 'what' 'when' 'where' 'which' 'while' 'white'\n",
            " 'who' 'whole' 'why' 'wife' 'will' 'with' 'without' 'woman' 'women' 'won'\n",
            " 'wonderful' 'work' 'works' 'world' 'worse' 'worst' 'worth' 'would'\n",
            " 'writing' 'written' 'wrong' 'year' 'years' 'yes' 'yet' 'you' 'young'\n",
            " 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into a training and validation (dev) set. We'll use the validation set to test our model. We'll use 90% of the data for training and 10% for testing."
      ],
      "metadata": {
        "id": "O_vqmxuNJKXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.9,random_state=123)"
      ],
      "metadata": {
        "id": "IgFqymeXcGzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use Multinomial Naive Bayes to do the classification. Create the model."
      ],
      "metadata": {
        "id": "Yz4X0a8sVEva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()"
      ],
      "metadata": {
        "id": "Yn-H8cvpZMr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "VHVdauzFJSWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.fit(X=X_train,y=y_train)"
      ],
      "metadata": {
        "id": "TFPY4JrcZkFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model on the validation set."
      ],
      "metadata": {
        "id": "UQTvGAtwJWn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_val)"
      ],
      "metadata": {
        "id": "xS22mi3sgr40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's calculate the accuracy of the model's predictions on the validation set."
      ],
      "metadata": {
        "id": "HESEphJ1VvjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_val,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_-Ah-Ig1bz",
        "outputId": "82e9a5d8-06f7-4968-e011-625de7c55ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7744\n"
          ]
        }
      ]
    }
  ]
}