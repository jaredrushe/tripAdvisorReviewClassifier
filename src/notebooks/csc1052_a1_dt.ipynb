{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsF8yRafNKjw"
      },
      "source": [
        "This notebook trains a binary classifier on a dataset which contains movie reviews which are labelled as containing either *positive* or *negative* sentiment towards the movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzUZxeMbRPoM"
      },
      "source": [
        "First we will install *sklearn* which we will be using to do the machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV8dcUsoOA_l",
        "outputId": "86a4800e-a80d-4d0a-dc70-168d4a713ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekmP1Ry1R00y"
      },
      "source": [
        "Next we will install the dataset. We will use the IMDB sentiment analysis dataset available from the [huggingface datasets library](https://huggingface.co/datasets/imdb) and described in [Maas et al. 2011](https://aclanthology.org/P11-1015.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd0bLG6nOE4D",
        "outputId": "4220261d-f7e7-446d-c5d2-83d476ddde43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: pandas in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: xxhash in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: filelock in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h6B6dXHSP6X"
      },
      "source": [
        "Now let's load the IMDB training set. We will print out the last instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOO5rQFHUg8D",
        "outputId": "60223425-2877-4e17-8860-833bf0fc9650"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")['train']\n",
        "print(imdb_dataset[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enwDYpN7Hwgw"
      },
      "source": [
        "Let's convert the training data into the format expected by scikit-learn - a list of input vectors (documents) and a list of associated output labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xfDeEMWq1o",
        "outputId": "80c0ceb8-ddb3-42f8-d31e-c6a676704678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "train_data = []\n",
        "train_data_labels = []\n",
        "for item in imdb_dataset:\n",
        "  train_data.append(item['text'])\n",
        "  train_data_labels.append(item['label'])\n",
        "print(train_data[-1])\n",
        "print(train_data_labels[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI6ab7wOIOu2"
      },
      "source": [
        "We'll use the CountVectorizer class to extract the words in each review as the features the algorithm will learn from. Each document is represented as a 500 dimension vector of word counts. Only the 500 most frequent words are used in this version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vDYo_rZkXZUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='word',max_features=500,lowercase=True)\n",
        "features = vectorizer.fit_transform(train_data).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7l9Xg1TTfkV"
      },
      "source": [
        "As a sanity check, let's check we have a 2-d array where each row is one of the 25,000 instances and each column is one of 200 words. Print out the words that will be used for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oW0zYH0TdPm",
        "outputId": "2b04d924-d583-42d3-d2df-2f060e41bff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25000, 500)\n",
            "['10' 'able' 'about' 'absolutely' 'act' 'acting' 'action' 'actor' 'actors'\n",
            " 'actually' 'after' 'again' 'against' 'all' 'almost' 'along' 'already'\n",
            " 'also' 'although' 'always' 'am' 'amazing' 'american' 'an' 'and' 'another'\n",
            " 'any' 'anyone' 'anything' 'are' 'around' 'art' 'as' 'at' 'audience'\n",
            " 'away' 'awful' 'back' 'bad' 'based' 'be' 'beautiful' 'because' 'become'\n",
            " 'becomes' 'been' 'before' 'beginning' 'behind' 'being' 'believe' 'best'\n",
            " 'better' 'between' 'big' 'bit' 'black' 'book' 'boring' 'both' 'boy' 'br'\n",
            " 'budget' 'but' 'by' 'called' 'came' 'camera' 'can' 'car' 'care' 'case'\n",
            " 'cast' 'certainly' 'character' 'characters' 'child' 'children' 'cinema'\n",
            " 'classic' 'close' 'come' 'comedy' 'comes' 'completely' 'could' 'couldn'\n",
            " 'couple' 'course' 'dark' 'day' 'days' 'dead' 'death' 'definitely'\n",
            " 'despite' 'dialogue' 'did' 'didn' 'different' 'direction' 'director' 'do'\n",
            " 'does' 'doesn' 'doing' 'don' 'done' 'down' 'drama' 'during' 'dvd' 'each'\n",
            " 'early' 'effects' 'either' 'else' 'end' 'ending' 'enjoy' 'enjoyed'\n",
            " 'enough' 'entertaining' 'entire' 'episode' 'especially' 'even' 'ever'\n",
            " 'every' 'everyone' 'everything' 'evil' 'example' 'excellent' 'face'\n",
            " 'fact' 'family' 'fan' 'fans' 'far' 'father' 'favorite' 'feel' 'felt'\n",
            " 'few' 'film' 'films' 'final' 'finally' 'find' 'fine' 'first' 'flick'\n",
            " 'for' 'found' 'friend' 'friends' 'from' 'full' 'fun' 'funny' 'game'\n",
            " 'genre' 'get' 'gets' 'getting' 'girl' 'give' 'given' 'gives' 'go' 'goes'\n",
            " 'going' 'good' 'got' 'great' 'guess' 'guy' 'guys' 'had' 'half' 'hand'\n",
            " 'hard' 'has' 'have' 'having' 'he' 'head' 'heart' 'help' 'her' 'here'\n",
            " 'high' 'him' 'himself' 'his' 'history' 'hollywood' 'home' 'hope' 'horror'\n",
            " 'house' 'how' 'however' 'human' 'humor' 'idea' 'if' 'in' 'instead'\n",
            " 'interesting' 'into' 'is' 'isn' 'it' 'its' 'itself' 'job' 'john' 'just'\n",
            " 'keep' 'kids' 'kill' 'killer' 'kind' 'know' 'last' 'later' 'laugh' 'lead'\n",
            " 'least' 'left' 'less' 'let' 'life' 'like' 'liked' 'line' 'lines' 'little'\n",
            " 'live' 'lives' 'll' 'long' 'look' 'looking' 'looks' 'lost' 'lot' 'love'\n",
            " 'loved' 'low' 'made' 'main' 'make' 'makes' 'making' 'man' 'many' 'may'\n",
            " 'maybe' 'me' 'mean' 'men' 'michael' 'might' 'mind' 'minutes' 'moments'\n",
            " 'money' 'more' 'most' 'mother' 'movie' 'movies' 'mr' 'much' 'music'\n",
            " 'must' 'my' 'name' 'need' 'never' 'new' 'next' 'nice' 'night' 'no' 'not'\n",
            " 'nothing' 'now' 'of' 'off' 'often' 'oh' 'old' 'on' 'once' 'one' 'only'\n",
            " 'or' 'original' 'other' 'others' 'our' 'out' 'over' 'overall' 'own'\n",
            " 'part' 'past' 'people' 'perfect' 'performance' 'performances' 'perhaps'\n",
            " 'person' 'picture' 'piece' 'place' 'play' 'played' 'playing' 'plays'\n",
            " 'plot' 'point' 'poor' 'pretty' 'probably' 'problem' 'production' 'put'\n",
            " 'quality' 'quite' 'rather' 're' 'read' 'real' 'really' 'reason'\n",
            " 'recommend' 'remember' 'rest' 'right' 'role' 'said' 'same' 'saw' 'say'\n",
            " 'scene' 'scenes' 'school' 'screen' 'script' 'second' 'see' 'seeing'\n",
            " 'seem' 'seemed' 'seems' 'seen' 'sense' 'series' 'set' 'several' 'sex'\n",
            " 'she' 'short' 'shot' 'should' 'show' 'shows' 'side' 'simply' 'since'\n",
            " 'small' 'so' 'some' 'someone' 'something' 'son' 'soon' 'sort' 'sound'\n",
            " 'special' 'star' 'stars' 'start' 'starts' 'still' 'story' 'stupid'\n",
            " 'style' 'such' 'supposed' 'sure' 'take' 'takes' 'tell' 'terrible' 'than'\n",
            " 'that' 'the' 'their' 'them' 'then' 'there' 'these' 'they' 'thing'\n",
            " 'things' 'think' 'this' 'those' 'though' 'thought' 'three' 'through'\n",
            " 'throughout' 'time' 'times' 'title' 'to' 'today' 'together' 'too' 'top'\n",
            " 'totally' 'town' 'tries' 'true' 'truly' 'try' 'trying' 'turn' 'turns'\n",
            " 'tv' 'two' 'under' 'understand' 'unfortunately' 'until' 'up' 'us' 'use'\n",
            " 'used' 've' 'version' 'very' 'video' 'viewer' 'want' 'wanted' 'wants'\n",
            " 'war' 'was' 'wasn' 'waste' 'watch' 'watched' 'watching' 'way' 'we' 'well'\n",
            " 'went' 'were' 'what' 'when' 'where' 'which' 'while' 'white' 'who' 'whole'\n",
            " 'why' 'wife' 'will' 'with' 'without' 'woman' 'women' 'won' 'wonderful'\n",
            " 'work' 'works' 'world' 'worse' 'worst' 'worth' 'would' 'writing'\n",
            " 'written' 'wrong' 'year' 'years' 'yes' 'yet' 'you' 'young' 'your']\n"
          ]
        }
      ],
      "source": [
        "print(features.shape)\n",
        "print(vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_vqmxuNJKXs"
      },
      "source": [
        "Split the data into a training and validation (dev) set. We'll use the validation set to test our model. We'll use 90% of the data for training and 10% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IgFqymeXcGzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.9,random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz4X0a8sVEva"
      },
      "source": [
        "We will use Decision Tree Classifier to do the classification. Create the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yn-H8cvpZMr9"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "model = tree.DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHVdauzFJSWY"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TFPY4JrcZkFZ"
      },
      "outputs": [],
      "source": [
        "model = model.fit(X=X_train,y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQTvGAtwJWn3"
      },
      "source": [
        "Test the model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xS22mi3sgr40"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HESEphJ1VvjQ"
      },
      "source": [
        "Now let's calculate the accuracy of the model's predictions on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_-Ah-Ig1bz",
        "outputId": "82e9a5d8-06f7-4968-e011-625de7c55ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6756\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_val,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate and print the confusion matrix for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[851 390]\n",
            " [421 838]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract and assign variable names to the true positive, false positive, true negative and false negative values.\n",
        "\n",
        "Use the relevant formulae to compute the true positive and true negative rates.\n",
        "\n",
        "These metrics provide a more detailed breakdown of the models accuracy in prediciting positive and negative cases individually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Positive Rate: 0.665608\n",
            "True Negative Rate: 0.685737\n"
          ]
        }
      ],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "tpr = tp / (tp + fn)\n",
        "print(f'True Positive Rate: {tpr:3f}')\n",
        "tnr = tn / (tn + fp)\n",
        "print(f'True Negative Rate: {tnr:3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the decision tree classifier is more reliable at predicting negative cases but the accuracy is low overall. \n",
        "\n",
        "Other models such as linear regression and naive bayes which have higher accuracy rates are clearly suitable for this type of data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
