{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to increase the accuracy of the K-Nearest Neighbours (KNN) algorithm on the validation set.\n",
    "\n",
    "I began by repeating the original first steps of loading the IMDB dataset and printing the last instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset(\"imdb\")['train']\n",
    "print(imdb_dataset[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, I converted the data to a list of input vectors and a list of associated output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story centers around Barry McKenzie who must go to England if he wishes to claim his inheritance. Being about the grossest Aussie shearer ever to set foot outside this great Nation of ours there is something of a culture clash and much fun and games ensue. The songs of Barry McKenzie(Barry Crocker) are highlights.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_data_labels = []\n",
    "for item in imdb_dataset:\n",
    "  train_data.append(item['text'])\n",
    "  train_data_labels.append(item['label'])\n",
    "print(train_data[-1])\n",
    "print(train_data_labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the KNN model from part two was **0.6092**.\n",
    "\n",
    "To improve this figure I experimented with a variety of additional parameters of the \"CountVectorizer\" function.\n",
    "\n",
    "Unfortunately for this particular model, some of these additions and alterations did not result in the accuracy score improving. \n",
    "\n",
    "Here are the changes I tried to implement that did not improve the performance of the model:\n",
    "\n",
    "**Adding n-grams:** `ngram_range=(1, 2)`\n",
    "\n",
    "By using just individual words you can often miss important sentiment that is expressed in combinations of words (e.g. \"good\" vs \"not good\"). I attempted to capture this added context using two word expressions (bigrams) in my list of algorithm features. It is likely that for this particular data, adding bigrams introduced irrelevant word combinations to the feature list, perhaps like \"the movie\", that include little to no sentiment and would therefore not be useful for classification purposes.\n",
    "\n",
    "**Increasing number of features:** `max_features=1000`\n",
    "\n",
    "I tinkered with the amount of the most common words to include in the feature list. I tried increasing it to 1000 to include even more distinctive words but this did not improve the accuracy. I also tried decreasing the number to 250 in case the original figure of 500 was too large and overfitting the data. This also lowered the accuracy, indicating that 500 was the ideal size for data of this type and volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the adjustment to the parameters that had the most positive influence on the predictive accuracy was:\n",
    "\n",
    "**Removing Stop Words:** `stop_words='english'`\n",
    "\n",
    "Scikit-learn provides a stop list of common English words (e.g. \"like\" \"this\" \"and\") that are typically considered irrelevant for text classification due to their lack of sentiment. I used this argument to filter these words out of the data so that they weren't included in the feature list. This meant that the model focused on words that carried more sentiment information and could establish more meaningful patterns that ultimately increased the overall accuracy score.\n",
    "\n",
    "After testing the model with various combinations and values of these CountVectorizer parameters, this was the version of the classifier that returned the highest accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',max_features=500,lowercase=True,stop_words='english')\n",
    "features = vectorizer.fit_transform(train_data).toarray()\n",
    "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.9,random_state=123)\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model = model.fit(X=X_train,y=y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the improvements to the CountVectorizer parameters only marginally increased the accuracy from 0.6092 to 0.622 (+0.0128).\n",
    "\n",
    "However, by using TfidfVectorizer as an alternative to CountVectorizer, I was able to significantly enhance the model. \n",
    "\n",
    "I chose TfidfVectorizer as it adjusts the weight of words based on how many reviews they appear in throughout the dataset. By reducing the weight of common words such as \"the\", distinctive words with more sentiment have more influence. \n",
    "\n",
    "Once again, I experimented with the stop word, n-gram and maximum feature parameters to maximise the algorithms efficiency. As expected, the stop word filtering was very beneficial but this time increasing the max features to 1000 also increased the accuracy score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final area I looked at to improve the model was altering the settings of the specific algorithm, in this case KNN.\n",
    "\n",
    "I chose to change the value for K from 3 to a value that would increase the accuracy.\n",
    "\n",
    "A value too small for K can capture too much noise in a dataset while a value too big can mean local patterns are overlooked.\n",
    "\n",
    "In the end, I found 5 was the value for K that gave me the highest accuracy score.\n",
    "\n",
    "The final version of the model that gave me the highest predictive accuracy over the validation set was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',max_features=1000,lowercase=True,stop_words='english')\n",
    "features = vectorizer.fit_transform(train_data).toarray()\n",
    "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.9,random_state=123)\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model = model.fit(X=X_train,y=y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been substantially improved from an accuracy score of 0.6092 to 0.7056 (+0.964)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the model to the test data, I loaded in the IMDB dataset again but this time selecting the \"test\" data instead of the \"train\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I caught this movie on the Sci-Fi channel recently. It actually turned out to be pretty decent as far as B-list horror/suspense films go. Two guys (one naive and one loud mouthed a**) take a road trip to stop a wedding but have the worst possible luck when a maniac in a freaky, make-shift tank/truck hybrid decides to play cat-and-mouse with them. Things are further complicated when they pick up a ridiculously whorish hitchhiker. What makes this film unique is that the combination of comedy and terror actually work in this movie, unlike so many others. The two guys are likable enough and there are some good chase/suspense scenes. Nice pacing and comic timing make this movie more than passable for the horror/slasher buff. Definitely worth checking out.', 'label': 1}\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "imdb_test = load_dataset(\"imdb\")['test']\n",
    "print(imdb_test[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then transformed each review in a feature vector with a corresponding label vector in the same way that the training set was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I caught this movie on the Sci-Fi channel recently. It actually turned out to be pretty decent as far as B-list horror/suspense films go. Two guys (one naive and one loud mouthed a**) take a road trip to stop a wedding but have the worst possible luck when a maniac in a freaky, make-shift tank/truck hybrid decides to play cat-and-mouse with them. Things are further complicated when they pick up a ridiculously whorish hitchhiker. What makes this film unique is that the combination of comedy and terror actually work in this movie, unlike so many others. The two guys are likable enough and there are some good chase/suspense scenes. Nice pacing and comic timing make this movie more than passable for the horror/slasher buff. Definitely worth checking out.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_data_labels = []\n",
    "for item in imdb_test:\n",
    "  test_data.append(item['text'])\n",
    "  test_data_labels.append(item['label'])\n",
    "print(test_data[-1])\n",
    "print(test_data_labels[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I applied the model to the test data and printed the final accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68888\n"
     ]
    }
   ],
   "source": [
    "test_pred=model.predict(vectorizer.transform(test_data).toarray())\n",
    "print(accuracy_score(test_data_labels,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuracy score was 0.68888. \n",
    "\n",
    "Although this score is far from perfect, it is a significantly more effective method than classifying the reviews at random which would have an accuracy score of ~0.5. This shows that the model does have some level of sophistication.\n",
    "\n",
    "The model has also been considerably refined to increase its performance. The accuracy score has been improved from 0.6092 originally on the training set to 0.6888 on the final test data. This is an increase of 0.0796 that was achieved through sensibly selecting combinations of classes, parameters and algorithm settings within the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
