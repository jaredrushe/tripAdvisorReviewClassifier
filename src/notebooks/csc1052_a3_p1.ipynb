{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzUZxeMbRPoM"
      },
      "source": [
        "The usual preliminaries....\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV8dcUsoOA_l",
        "outputId": "28bdbd96-1a13-4bec-b0ea-cc3e483df6a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd0bLG6nOE4D",
        "outputId": "483f90b1-96a3-4179-a029-4a813c37c7c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.0.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2024.6.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rushej2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rushej2\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\rushej2\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOO5rQFHUg8D",
        "outputId": "7b3a9818-59d7-46c5-ec19-e56fcf40340d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H8xfDeEMWq1o"
      },
      "outputs": [],
      "source": [
        "train_data = []\n",
        "train_data_labels = []\n",
        "for item in imdb_dataset:\n",
        "  train_data.append(item['text'])\n",
        "  train_data_labels.append(item['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vDYo_rZkXZUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer='word',max_features=1000,lowercase=True,stop_words='english',ngram_range=(1,2))\n",
        "features = vectorizer.fit_transform(train_data).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IgFqymeXcGzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(features,train_data_labels,train_size=0.9,random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz4X0a8sVEva"
      },
      "source": [
        "We will use three Decision Tree models, each one using a different splitting criterion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Yn-H8cvpZMr9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_dt1 = DecisionTreeClassifier(criterion='log_loss')\n",
        "model_dt2 = DecisionTreeClassifier(criterion='gini')\n",
        "model_dt3 = DecisionTreeClassifier(criterion='entropy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLNBLWY5o3kS"
      },
      "source": [
        "Train the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TFPY4JrcZkFZ"
      },
      "outputs": [],
      "source": [
        "model_dt1 = model_dt1.fit(X=X_train,y=y_train)\n",
        "model_dt2 = model_dt2.fit(X=X_train,y=y_train)\n",
        "model_dt3 = model_dt3.fit(X=X_train,y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQTvGAtwJWn3"
      },
      "source": [
        "Test the models on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xS22mi3sgr40"
      },
      "outputs": [],
      "source": [
        "y_pred_dt1 = model_dt1.predict(X_val)\n",
        "y_pred_dt2 = model_dt2.predict(X_val)\n",
        "y_pred_dt3 = model_dt3.predict(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HESEphJ1VvjQ"
      },
      "source": [
        "Now let's calculate the accuracy of the models' predictions on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_-Ah-Ig1bz",
        "outputId": "47c3f9f3-7c51-4f9c-fbfb-a8c9868c55a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree 1 0.6884\n",
            "[[861 380]\n",
            " [399 860]]\n",
            "\n",
            "Decision Tree 2 0.704\n",
            "[[872 369]\n",
            " [371 888]]\n",
            "\n",
            "Decision Tree 3 0.7004\n",
            "[[887 354]\n",
            " [395 864]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(\"Decision Tree 1\", accuracy_score(y_val,y_pred_dt1))\n",
        "print(confusion_matrix(y_val,y_pred_dt1))\n",
        "print()\n",
        "print(\"Decision Tree 2\", accuracy_score(y_val,y_pred_dt2))\n",
        "print(confusion_matrix(y_val,y_pred_dt2))\n",
        "print()\n",
        "print(\"Decision Tree 3\", accuracy_score(y_val,y_pred_dt3))\n",
        "print(confusion_matrix(y_val,y_pred_dt3))\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiGBrsQjo6CL"
      },
      "source": [
        "Now create the voting ensemble..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I developed the ensemble model by storing the binary classification for each prediction in a list and then determining the ensemble's prediction by selecting the most common element in that list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy: 0.7088\n",
            "Confusion Matrix:\n",
            " [[888 353]\n",
            " [375 884]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "y_pred_ensemble = []\n",
        "\n",
        "for i in range(len(y_pred_dt1)):\n",
        "    votes = [y_pred_dt1[i], y_pred_dt2[i], y_pred_dt3[i]]\n",
        "    if votes.count(1) > votes.count(0):\n",
        "        y_pred_ensemble.append(1)\n",
        "    else:\n",
        "        y_pred_ensemble.append(0)\n",
        "\n",
        "accuracy = accuracy_score(y_val, y_pred_ensemble)\n",
        "cm = confusion_matrix(y_val, y_pred_ensemble)\n",
        "\n",
        "print(\"Ensemble Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ensemble did improve the accuracy on the IMDB dataset but only very slightly. This is likely due to the individual decision tree models being very similar and making the same mistakes. Perhaps a more effective approach would be to use more diverse individual models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for Easy Review:\n",
            "\n",
            "Review: Wow, this was fantastic! As I was watching it, I asked myself, 'Is this the best animated movie I've ever seen?' I think the answer is 'yes.'\n",
            "Model 1 Prediction: Positive (Correct)\n",
            "Model 2 Prediction: Positive (Correct)\n",
            "Model 3 Prediction: Positive (Correct)\n",
            "Ensemble Prediction: Positive (Correct)\n",
            "\n",
            "Review: Yeah, I must admit, I love this movie. Which is nothing to be ashamed of; great movie, great directing, great set, great scale, great canvas, great story.\n",
            "Model 1 Prediction: Positive (Correct)\n",
            "Model 2 Prediction: Positive (Correct)\n",
            "Model 3 Prediction: Positive (Correct)\n",
            "Ensemble Prediction: Positive (Correct)\n",
            "\n",
            "Review: This is the finest movie I have ever seen of the drama kind; it has everything to make an excellent movie. All the actors play an outstanding role.\n",
            "Model 1 Prediction: Positive (Correct)\n",
            "Model 2 Prediction: Positive (Correct)\n",
            "Model 3 Prediction: Positive (Correct)\n",
            "Ensemble Prediction: Positive (Correct)\n",
            "\n",
            "Review: I have no idea how anyone could like this dull, uninspiring movie. It was very, very predictable. The leading actress had no talent.\n",
            "Model 1 Prediction: Negative (Correct)\n",
            "Model 2 Prediction: Negative (Correct)\n",
            "Model 3 Prediction: Negative (Correct)\n",
            "Ensemble Prediction: Negative (Correct)\n",
            "\n",
            "Review: This movie is probably one of the worst movies I have ever seen. Don't waste your time watching this. I almost turned this movie off watching it.\n",
            "Model 1 Prediction: Negative (Correct)\n",
            "Model 2 Prediction: Negative (Correct)\n",
            "Model 3 Prediction: Negative (Correct)\n",
            "Ensemble Prediction: Negative (Correct)\n",
            "\n",
            "Review: If you want a quick and easy way to punish your kids, take them to see this film. This overlong and boring movie will put them to sleep.\n",
            "Model 1 Prediction: Positive (Incorrect)\n",
            "Model 2 Prediction: Negative (Correct)\n",
            "Model 3 Prediction: Negative (Correct)\n",
            "Ensemble Prediction: Negative (Correct)\n",
            "\n",
            "Individual Accuracies:\n",
            "Model 1 Accuracy: 0.8333\n",
            "Model 2 Accuracy: 1.0000\n",
            "Model 3 Accuracy: 1.0000\n",
            "Ensemble Accuracy: 1.0000\n",
            "\n",
            "Confusion Matrix for Ensemble Predictions:\n",
            " [[3 0]\n",
            " [0 3]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "easy_reviews = [\n",
        "    \"Wow, this was fantastic! As I was watching it, I asked myself, 'Is this the best animated movie I've ever seen?' I think the answer is 'yes.'\",\n",
        "    \"Yeah, I must admit, I love this movie. Which is nothing to be ashamed of; great movie, great directing, great set, great scale, great canvas, great story.\",\n",
        "    \"This is the finest movie I have ever seen of the drama kind; it has everything to make an excellent movie. All the actors play an outstanding role.\",\n",
        "    \"I have no idea how anyone could like this dull, uninspiring movie. It was very, very predictable. The leading actress had no talent.\",\n",
        "    \"This movie is probably one of the worst movies I have ever seen. Don't waste your time watching this. I almost turned this movie off watching it.\",\n",
        "    \"If you want a quick and easy way to punish your kids, take them to see this film. This overlong and boring movie will put them to sleep.\"\n",
        "]\n",
        "\n",
        "X_test = vectorizer.transform(easy_reviews).toarray()\n",
        "\n",
        "y_pred_dt1 = model_dt1.predict(X_test)\n",
        "y_pred_dt2 = model_dt2.predict(X_test)\n",
        "y_pred_dt3 = model_dt3.predict(X_test)\n",
        "\n",
        "test_labels = [1, 1, 1, 0, 0, 0]\n",
        "\n",
        "y_pred_ensemble = []\n",
        "for i in range(len(y_pred_dt1)):\n",
        "    votes = [y_pred_dt1[i], y_pred_dt2[i], y_pred_dt3[i]]\n",
        "    y_pred_ensemble.append(1 if votes.count(1) > votes.count(0) else 0)\n",
        "\n",
        "accuracy_dt1 = accuracy_score(test_labels, y_pred_dt1)\n",
        "accuracy_dt2 = accuracy_score(test_labels, y_pred_dt2)\n",
        "accuracy_dt3 = accuracy_score(test_labels, y_pred_dt3)\n",
        "accuracy_ensemble = accuracy_score(test_labels, y_pred_ensemble)\n",
        "\n",
        "print(\"Predictions for Easy Review:\")\n",
        "for i, review in enumerate(easy_reviews):\n",
        "    correct_dt1 = 'Correct' if y_pred_dt1[i] == test_labels[i] else 'Incorrect'\n",
        "    correct_dt2 = 'Correct' if y_pred_dt2[i] == test_labels[i] else 'Incorrect'\n",
        "    correct_dt3 = 'Correct' if y_pred_dt3[i] == test_labels[i] else 'Incorrect'\n",
        "    correct_ensemble = 'Correct' if y_pred_ensemble[i] == test_labels[i] else 'Incorrect'\n",
        "    \n",
        "    print(f\"\\nReview: {review}\")\n",
        "    print(f\"Model 1 Prediction: {'Positive' if y_pred_dt1[i] == 1 else 'Negative'} ({correct_dt1})\")\n",
        "    print(f\"Model 2 Prediction: {'Positive' if y_pred_dt2[i] == 1 else 'Negative'} ({correct_dt2})\")\n",
        "    print(f\"Model 3 Prediction: {'Positive' if y_pred_dt3[i] == 1 else 'Negative'} ({correct_dt3})\")\n",
        "    print(f\"Ensemble Prediction: {'Positive' if y_pred_ensemble[i] == 1 else 'Negative'} ({correct_ensemble})\")\n",
        "\n",
        "print(\"\\nIndividual Accuracies:\")\n",
        "print(f\"Model 1 Accuracy: {accuracy_dt1:.4f}\")\n",
        "print(f\"Model 2 Accuracy: {accuracy_dt2:.4f}\")\n",
        "print(f\"Model 3 Accuracy: {accuracy_dt3:.4f}\")\n",
        "print(f\"Ensemble Accuracy: {accuracy_ensemble:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred_ensemble)\n",
        "print(\"\\nConfusion Matrix for Ensemble Predictions:\\n\", cm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected the models were all very successful at predicting the easy reviews. The individual models predicted almost each review correct so therefore the ensemble was also right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for Each Review:\n",
            "\n",
            "Review: For a horror film, it had me laughing out loud from start to finish—truly a unique experience for the genre.\n",
            "Model 1 Prediction: Positive\n",
            "Model 2 Prediction: Positive\n",
            "Model 3 Prediction: Positive\n",
            "Ensemble Prediction: Positive\n",
            "\n",
            "Review: What a delightful waste of time! I love sitting through a three hour film that goes nowhere. I’m looking forward to the sequel already!]\n",
            "Model 1 Prediction: Negative\n",
            "Model 2 Prediction: Negative\n",
            "Model 3 Prediction: Negative\n",
            "Ensemble Prediction: Negative\n",
            "\n",
            "Review: Almost everything about my day at the cinema was brilliant; the popcorn was lovely, the seats were fantastic and the tickets were great value. The film itself though, the less said the better.\n",
            "Model 1 Prediction: Positive\n",
            "Model 2 Prediction: Positive\n",
            "Model 3 Prediction: Positive\n",
            "Ensemble Prediction: Positive\n",
            "\n",
            "Review: I was dreading watching this movie as I had been told the acting was awful and the plot was confusing. However, having watched it myself, I completely disagree. Those reviews were absolute nonsense.\n",
            "Model 1 Prediction: Negative\n",
            "Model 2 Prediction: Negative\n",
            "Model 3 Prediction: Negative\n",
            "Ensemble Prediction: Negative\n",
            "\n",
            "Review: I wanted to turn this film off from the moment it began. It was a horrible and unsettling experience, exactly how a horror movie should be. Despite the awful fear I felt, I couldn’t look away.\n",
            "Model 1 Prediction: Negative\n",
            "Model 2 Prediction: Negative\n",
            "Model 3 Prediction: Negative\n",
            "Ensemble Prediction: Negative\n",
            "\n",
            "Review: I usually hate the lead actor but his performance wasn’t a complete disaster this time around. I was shocked that he didn’t totally ruin the film and it was actually quite enjoyable.\n",
            "Model 1 Prediction: Positive\n",
            "Model 2 Prediction: Positive\n",
            "Model 3 Prediction: Positive\n",
            "Ensemble Prediction: Positive\n",
            "\n",
            "Individual Accuracies:\n",
            "Model 1 Accuracy: 0.3333\n",
            "Model 2 Accuracy: 0.3333\n",
            "Model 3 Accuracy: 0.3333\n",
            "Ensemble Accuracy: 0.3333\n",
            "\n",
            "Confusion Matrix for Ensemble Predictions:\n",
            " [[1 2]\n",
            " [2 1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "adversarial_reviews = [\n",
        "    \"For a horror film, it had me laughing out loud from start to finish—truly a unique experience for the genre.\",\n",
        "    \"What a delightful waste of time! I love sitting through a three hour film that goes nowhere. I’m looking forward to the sequel already!]\",\n",
        "    \"Almost everything about my day at the cinema was brilliant; the popcorn was lovely, the seats were fantastic and the tickets were great value. The film itself though, the less said the better.\",\n",
        "    \"I was dreading watching this movie as I had been told the acting was awful and the plot was confusing. However, having watched it myself, I completely disagree. Those reviews were absolute nonsense.\",\n",
        "    \"I wanted to turn this film off from the moment it began. It was a horrible and unsettling experience, exactly how a horror movie should be. Despite the awful fear I felt, I couldn’t look away.\",\n",
        "    \"I usually hate the lead actor but his performance wasn’t a complete disaster this time around. I was shocked that he didn’t totally ruin the film and it was actually quite enjoyable.\"]\n",
        "   \n",
        "X_test = vectorizer.transform(adversarial_reviews).toarray()\n",
        "\n",
        "y_pred_dt1 = model_dt1.predict(X_test)\n",
        "y_pred_dt2 = model_dt2.predict(X_test)\n",
        "y_pred_dt3 = model_dt3.predict(X_test)\n",
        "\n",
        "\n",
        "test_labels = [0, 0, 0, 1, 1, 1]\n",
        "\n",
        "y_pred_ensemble = []\n",
        "for i in range(len(y_pred_dt1)):\n",
        "    votes = [y_pred_dt1[i], y_pred_dt2[i], y_pred_dt3[i]]\n",
        "    y_pred_ensemble.append(1 if votes.count(1) > votes.count(0) else 0)\n",
        "\n",
        "accuracy_dt1 = accuracy_score(test_labels, y_pred_dt1)\n",
        "accuracy_dt2 = accuracy_score(test_labels, y_pred_dt2)\n",
        "accuracy_dt3 = accuracy_score(test_labels, y_pred_dt3)\n",
        "accuracy_ensemble = accuracy_score(test_labels, y_pred_ensemble)\n",
        "\n",
        "print(\"Predictions for Each Review:\")\n",
        "for i, review in enumerate(adversarial_reviews):\n",
        "    print(f\"\\nReview: {review}\")\n",
        "    print(f\"Model 1 Prediction: {'Positive' if y_pred_dt1[i] == 1 else 'Negative'}\")\n",
        "    print(f\"Model 2 Prediction: {'Positive' if y_pred_dt2[i] == 1 else 'Negative'}\")\n",
        "    print(f\"Model 3 Prediction: {'Positive' if y_pred_dt3[i] == 1 else 'Negative'}\")\n",
        "    print(f\"Ensemble Prediction: {'Positive' if y_pred_ensemble[i] == 1 else 'Negative'}\")\n",
        "\n",
        "print(\"\\nIndividual Accuracies:\")\n",
        "print(f\"Model 1 Accuracy: {accuracy_dt1:.4f}\")\n",
        "print(f\"Model 2 Accuracy: {accuracy_dt2:.4f}\")\n",
        "print(f\"Model 3 Accuracy: {accuracy_dt3:.4f}\")\n",
        "print(f\"Ensemble Accuracy: {accuracy_ensemble:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(test_labels, y_pred_ensemble)\n",
        "print(\"\\nConfusion Matrix for Ensemble Predictions:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The models were far less successful when predicting the sentiment of the adversarial test set due to the more nuanced language techniques. The ensemble was better than the naive bayes classifier that I used in Assignment 2 but after analysing the individual review predictions it was clear that the three contributing models were too similar. The 3 decision tree classifiers almost always voted for the same sentiment regardless of whether they were right or wrong. The models were clearly identifying the same important features and making the same mistakes which defeats the purpose of the ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Overall Accuracies (Combined Test Set):\n",
            "Model 1 Accuracy: 0.6667\n",
            "Model 2 Accuracy: 0.6667\n",
            "Model 3 Accuracy: 0.6667\n",
            "Ensemble Accuracy: 0.6667\n",
            "\n",
            "Confusion Matrix for Ensemble (Combined Test Set):\n",
            " [[4 2]\n",
            " [2 4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "combined_labels = [1, 1, 1, 0, 0, 0] + [0, 0, 0, 1, 1, 1]\n",
        "\n",
        "combined_reviews = easy_reviews + adversarial_reviews\n",
        "X_test_combined = vectorizer.transform(combined_reviews).toarray()\n",
        "\n",
        "y_pred_dt1 = model_dt1.predict(X_test_combined)\n",
        "y_pred_dt2 = model_dt2.predict(X_test_combined)\n",
        "y_pred_dt3 = model_dt3.predict(X_test_combined)\n",
        "\n",
        "y_pred_ensemble = []\n",
        "for i in range(len(y_pred_dt1_combined)):\n",
        "    votes = [y_pred_dt1[i], y_pred_dt2[i], y_pred_dt3[i]]\n",
        "    y_pred_ensemble.append(1 if votes.count(1) > votes.count(0) else 0)\n",
        "\n",
        "# Calculate accuracy scores for each model and the ensemble on the combined test set\n",
        "accuracy_dt1_combined = accuracy_score(combined_labels, y_pred_dt1)\n",
        "accuracy_dt2_combined = accuracy_score(combined_labels, y_pred_dt2)\n",
        "accuracy_dt3_combined = accuracy_score(combined_labels, y_pred_dt3)\n",
        "accuracy_ensemble_combined = accuracy_score(combined_labels, y_pred_ensemble)\n",
        "\n",
        "cm_ensemble = confusion_matrix(combined_labels, y_pred_ensemble)\n",
        "\n",
        "# Print overall accuracy and confusion matrices\n",
        "print(\"\\nOverall Accuracies (Combined Test Set):\")\n",
        "print(f\"Model 1 Accuracy: {accuracy_dt1_combined:.4f}\")\n",
        "print(f\"Model 2 Accuracy: {accuracy_dt2_combined:.4f}\")\n",
        "print(f\"Model 3 Accuracy: {accuracy_dt3_combined:.4f}\")\n",
        "print(f\"Ensemble Accuracy: {accuracy_ensemble_combined:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix for Ensemble (Combined Test Set):\\n\", cm_ensemble)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, the ensemble had a very similar performance on my own test set as it did on the IMDB reviews. This makes sense as between the easy and adversarial set there was a good mix of easy and hard reviews to classify which would have also been captured in the IMDB set due to its large sample size. This indicates that my own test set was a fair way to trial and analyse the ensemble model. My biggest learning from this was that ensembles can certainly be a more effective way to design a classificaation model. However, it's very important to choose a diverse and large set of individual models so that you can reduce bias and improve overall accuracy by capturing different patterns in the data. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
